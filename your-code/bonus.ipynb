{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge: Spiral Data Classification\n",
    "\n",
    "Now that you completed Challenge 2, you know you can use the Tensorflow Playground to experiment the hyperparameters of your deep learning model. If you are brave enough to take on this challenge, we present you the spiral data generated by codes and you will replicate your model built visually in the Tensorflow Playground with Python codes.\n",
    "\n",
    "Below are the codes to generate the spiral dataset. Read the remarks and execute the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import hypot, cos, sin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "A function to generate X/Y data points that will form a spiral.\n",
    "\"\"\"\n",
    "def spiral(radius, step, resolution=.1, angle=0.0, start=0.0):\n",
    "    dist = start\n",
    "    coords=[]\n",
    "    while dist*hypot(cos(angle),sin(angle))<radius:\n",
    "        cord=[]\n",
    "        cord.append(dist*cos(angle))\n",
    "        cord.append(dist*sin(angle))\n",
    "        coords.append(cord)\n",
    "        dist+=step\n",
    "        angle+=resolution\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two sets of spiral data points with opposite angles\n",
    "data_1 = np.array(spiral(1000, 5, angle=0))\n",
    "data_2 = np.array(spiral(1000, 5, angle=180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the two datasets to visualize the spirals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a, b = data_1.T\n",
    "plt.scatter(a, b, s=5)\n",
    "\n",
    "aa, bb = data_2.T\n",
    "plt.scatter(aa, bb, s=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zluca\\AppData\\Local\\Temp\\ipykernel_22764\\2939864048.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df1.append(df2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    200\n",
       "1    200\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two spiral datasets into one\n",
    "\n",
    "df1 = pd.DataFrame(data=data_1, columns=[\"X\", \"Y\"])\n",
    "df1[\"CLASS\"] = 0\n",
    "\n",
    "df2 = pd.DataFrame(data=data_2, columns=[\"X\", \"Y\"])\n",
    "df2[\"CLASS\"] = 1\n",
    "\n",
    "df = df1.append(df2)\n",
    "df['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build a neural network with Tensorflow to classify `df`. See how low data loss and how high accuracy can you achieve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zluca\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zluca\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Create an L2 regularization object\n",
    "l2_regularizer = tf.keras.regularizers.L2(0.01)\n",
    "\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu', input_shape=(2,)))\n",
    "model.add(tf.keras.layers.Dense(7, activation='relu', ))\n",
    "model.add(tf.keras.layers.Dense(6, activation='relu', ))\n",
    "model.add(tf.keras.layers.Dense(5, activation='relu', ))\n",
    "model.add(tf.keras.layers.Dense(4, activation='relu', ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 24        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194 (776.00 Byte)\n",
      "Trainable params: 194 (776.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "              loss='mse', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.975021</td>\n",
       "      <td>0.499167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.800666</td>\n",
       "      <td>1.986693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.330047</td>\n",
       "      <td>4.432803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.421220</td>\n",
       "      <td>7.788367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>8.644721</td>\n",
       "      <td>-974.961676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>106.478547</td>\n",
       "      <td>-974.198296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>204.240898</td>\n",
       "      <td>-963.592578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>300.939178</td>\n",
       "      <td>-943.151955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>395.581665</td>\n",
       "      <td>-912.984198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              X           Y\n",
       "0      0.000000    0.000000\n",
       "1      4.975021    0.499167\n",
       "2      9.800666    1.986693\n",
       "3     14.330047    4.432803\n",
       "4     18.421220    7.788367\n",
       "..          ...         ...\n",
       "195    8.644721 -974.961676\n",
       "196  106.478547 -974.198296\n",
       "197  204.240898 -963.592578\n",
       "198  300.939178 -943.151955\n",
       "199  395.581665 -912.984198\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "195    1\n",
       "196    1\n",
       "197    1\n",
       "198    1\n",
       "199    1\n",
       "Name: CLASS, Length: 400, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.drop(columns='CLASS')\n",
    "y = df['CLASS']\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/770\n",
      "WARNING:tensorflow:From c:\\Users\\zluca\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\zluca\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "32/32 [==============================] - 2s 2ms/step - loss: 45.2363 - accuracy: 0.4594\n",
      "Epoch 2/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.4688\n",
      "Epoch 3/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.4500\n",
      "Epoch 4/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.1469\n",
      "Epoch 5/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.0312\n",
      "Epoch 6/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.0188\n",
      "Epoch 7/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.0250\n",
      "Epoch 8/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.0156\n",
      "Epoch 9/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.0281\n",
      "Epoch 10/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.0344\n",
      "Epoch 11/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.0188\n",
      "Epoch 12/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.0281\n",
      "Epoch 13/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.0312\n",
      "Epoch 14/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.0250\n",
      "Epoch 15/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.0219\n",
      "Epoch 16/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.0312\n",
      "Epoch 17/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.0219\n",
      "Epoch 18/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3898 - accuracy: 0.0312\n",
      "Epoch 19/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3803 - accuracy: 0.0500\n",
      "Epoch 20/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.0531\n",
      "Epoch 21/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.0562\n",
      "Epoch 22/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.1063\n",
      "Epoch 23/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.1125\n",
      "Epoch 24/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.4531\n",
      "Epoch 25/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.1063\n",
      "Epoch 26/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3680 - accuracy: 0.3906\n",
      "Epoch 27/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.3375\n",
      "Epoch 28/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.1781\n",
      "Epoch 29/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.3094\n",
      "Epoch 30/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.1406\n",
      "Epoch 31/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.4437\n",
      "Epoch 32/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.1469\n",
      "Epoch 33/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.3812\n",
      "Epoch 34/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.2438\n",
      "Epoch 35/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.2156\n",
      "Epoch 36/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.2750\n",
      "Epoch 37/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.3656\n",
      "Epoch 38/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3239 - accuracy: 0.1312\n",
      "Epoch 39/770\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3217 - accuracy: 0.3625\n",
      "Epoch 40/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.2812\n",
      "Epoch 41/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.3094\n",
      "Epoch 42/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.4281\n",
      "Epoch 43/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.1813\n",
      "Epoch 44/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.4250\n",
      "Epoch 45/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.4344\n",
      "Epoch 46/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.3531\n",
      "Epoch 47/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.3500\n",
      "Epoch 48/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.4844\n",
      "Epoch 49/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.3938\n",
      "Epoch 50/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.4344\n",
      "Epoch 51/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.3781\n",
      "Epoch 52/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.3156\n",
      "Epoch 53/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.4344\n",
      "Epoch 54/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.4563\n",
      "Epoch 55/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.2750\n",
      "Epoch 56/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.4625\n",
      "Epoch 57/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.4250\n",
      "Epoch 58/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.4375\n",
      "Epoch 59/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.4531\n",
      "Epoch 60/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.4656\n",
      "Epoch 61/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.3094\n",
      "Epoch 62/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.4500\n",
      "Epoch 63/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.4250\n",
      "Epoch 64/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.4094\n",
      "Epoch 65/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.2719\n",
      "Epoch 66/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.4844\n",
      "Epoch 67/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.3656\n",
      "Epoch 68/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.4625\n",
      "Epoch 69/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.4875\n",
      "Epoch 70/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3160 - accuracy: 0.4594\n",
      "Epoch 71/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.2562\n",
      "Epoch 72/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3153 - accuracy: 0.4688\n",
      "Epoch 73/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.4156\n",
      "Epoch 74/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.4844\n",
      "Epoch 75/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.4781\n",
      "Epoch 76/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.2719\n",
      "Epoch 77/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.4625\n",
      "Epoch 78/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3153 - accuracy: 0.4375\n",
      "Epoch 79/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.4594\n",
      "Epoch 80/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3137 - accuracy: 0.4656\n",
      "Epoch 81/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3147 - accuracy: 0.4594\n",
      "Epoch 82/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.4469\n",
      "Epoch 83/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.4781\n",
      "Epoch 84/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.4750\n",
      "Epoch 85/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.4625\n",
      "Epoch 86/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3163 - accuracy: 0.4719\n",
      "Epoch 87/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.5031\n",
      "Epoch 88/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.3906\n",
      "Epoch 89/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.2562\n",
      "Epoch 90/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.3656\n",
      "Epoch 91/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.4938\n",
      "Epoch 92/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.4656\n",
      "Epoch 93/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.4906\n",
      "Epoch 94/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.5000\n",
      "Epoch 95/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.5031\n",
      "Epoch 96/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.4437\n",
      "Epoch 97/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.4344\n",
      "Epoch 98/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.4531\n",
      "Epoch 99/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.4031\n",
      "Epoch 100/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.4844\n",
      "Epoch 101/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.5063\n",
      "Epoch 102/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.4906\n",
      "Epoch 103/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3153 - accuracy: 0.2094\n",
      "Epoch 104/770\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3148 - accuracy: 0.4094\n",
      "Epoch 105/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.1719\n",
      "Epoch 106/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.4969\n",
      "Epoch 107/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.3844\n",
      "Epoch 108/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 0.1625\n",
      "Epoch 109/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.4594\n",
      "Epoch 110/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.5031\n",
      "Epoch 111/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.4969\n",
      "Epoch 112/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3132 - accuracy: 0.4875\n",
      "Epoch 113/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.4656\n",
      "Epoch 114/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.0125\n",
      "Epoch 115/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.3594\n",
      "Epoch 116/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.0594\n",
      "Epoch 117/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.4281\n",
      "Epoch 118/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.1375\n",
      "Epoch 119/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.5031\n",
      "Epoch 120/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3128 - accuracy: 0.1000\n",
      "Epoch 121/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3120 - accuracy: 0.5031\n",
      "Epoch 122/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.0781\n",
      "Epoch 123/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.5000\n",
      "Epoch 124/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.0281\n",
      "Epoch 125/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.3250\n",
      "Epoch 126/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.4906\n",
      "Epoch 127/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.0500\n",
      "Epoch 128/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.4875\n",
      "Epoch 129/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.4375\n",
      "Epoch 130/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.0781\n",
      "Epoch 131/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.2313\n",
      "Epoch 132/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.2969\n",
      "Epoch 133/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.2969\n",
      "Epoch 134/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.3531\n",
      "Epoch 135/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.2969\n",
      "Epoch 136/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.2781\n",
      "Epoch 137/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.4500\n",
      "Epoch 138/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.4906\n",
      "Epoch 139/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.1281\n",
      "Epoch 140/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.5031\n",
      "Epoch 141/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3115 - accuracy: 0.1594\n",
      "Epoch 142/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.1844\n",
      "Epoch 143/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.2594\n",
      "Epoch 144/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.2281\n",
      "Epoch 145/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.5156\n",
      "Epoch 146/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.3719\n",
      "Epoch 147/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.2531\n",
      "Epoch 148/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.0906\n",
      "Epoch 149/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.2156\n",
      "Epoch 150/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.4906\n",
      "Epoch 151/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.0125\n",
      "Epoch 152/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.2062\n",
      "Epoch 153/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3112 - accuracy: 0.2594\n",
      "Epoch 154/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3107 - accuracy: 0.3719\n",
      "Epoch 155/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.2219\n",
      "Epoch 156/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.3313\n",
      "Epoch 157/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.3000\n",
      "Epoch 158/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.3562\n",
      "Epoch 159/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.0812\n",
      "Epoch 160/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.5156\n",
      "Epoch 161/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.1375\n",
      "Epoch 162/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.4062\n",
      "Epoch 163/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.1312\n",
      "Epoch 164/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3118 - accuracy: 0.3313\n",
      "Epoch 165/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.2812\n",
      "Epoch 166/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.4906\n",
      "Epoch 167/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.3438\n",
      "Epoch 168/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3109 - accuracy: 0.0188\n",
      "Epoch 169/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3115 - accuracy: 0.2875\n",
      "Epoch 170/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.3719\n",
      "Epoch 171/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.1875\n",
      "Epoch 172/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.2562\n",
      "Epoch 173/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.3125\n",
      "Epoch 174/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.2125\n",
      "Epoch 175/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.1656\n",
      "Epoch 176/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.5000\n",
      "Epoch 177/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.2062\n",
      "Epoch 178/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.4531\n",
      "Epoch 179/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.0406\n",
      "Epoch 180/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.4563\n",
      "Epoch 181/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.0031\n",
      "Epoch 182/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.4594\n",
      "Epoch 183/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.1375\n",
      "Epoch 184/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.2406\n",
      "Epoch 185/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.2656\n",
      "Epoch 186/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.5031\n",
      "Epoch 187/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.1750\n",
      "Epoch 188/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.3531\n",
      "Epoch 189/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.2188\n",
      "Epoch 190/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.2688\n",
      "Epoch 191/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.2031\n",
      "Epoch 192/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.4688\n",
      "Epoch 193/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.1813\n",
      "Epoch 194/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3109 - accuracy: 0.1063\n",
      "Epoch 195/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.3562\n",
      "Epoch 196/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.1344\n",
      "Epoch 197/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.5000\n",
      "Epoch 198/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.0906\n",
      "Epoch 199/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3107 - accuracy: 0.1219\n",
      "Epoch 200/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.3531\n",
      "Epoch 201/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.1844\n",
      "Epoch 202/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.3844\n",
      "Epoch 203/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.3281\n",
      "Epoch 204/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.2969\n",
      "Epoch 205/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.1688\n",
      "Epoch 206/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.3219\n",
      "Epoch 207/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.5031\n",
      "Epoch 208/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.0750\n",
      "Epoch 209/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.4875\n",
      "Epoch 210/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.1844\n",
      "Epoch 211/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.2344\n",
      "Epoch 212/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3109 - accuracy: 0.4781\n",
      "Epoch 213/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.1875\n",
      "Epoch 214/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.1281\n",
      "Epoch 215/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.4688\n",
      "Epoch 216/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.3375\n",
      "Epoch 217/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.0938\n",
      "Epoch 218/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.4062\n",
      "Epoch 219/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.0188\n",
      "Epoch 220/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.3469\n",
      "Epoch 221/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.1531\n",
      "Epoch 222/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.5000\n",
      "Epoch 223/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.1469\n",
      "Epoch 224/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.4906\n",
      "Epoch 225/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.0156\n",
      "Epoch 226/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.4969\n",
      "Epoch 227/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.1719\n",
      "Epoch 228/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.3938\n",
      "Epoch 229/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3111 - accuracy: 0.0312\n",
      "Epoch 230/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.3281\n",
      "Epoch 231/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.4781\n",
      "Epoch 232/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.0938\n",
      "Epoch 233/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.4875\n",
      "Epoch 234/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.4719\n",
      "Epoch 235/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.0625\n",
      "Epoch 236/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.2344\n",
      "Epoch 237/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.1187\n",
      "Epoch 238/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.2438\n",
      "Epoch 239/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.1250\n",
      "Epoch 240/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.3406\n",
      "Epoch 241/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.0750\n",
      "Epoch 242/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.3562\n",
      "Epoch 243/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.0656\n",
      "Epoch 244/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.3688\n",
      "Epoch 245/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.0000e+00\n",
      "Epoch 246/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.3688\n",
      "Epoch 247/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.1187\n",
      "Epoch 248/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.2969\n",
      "Epoch 249/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.0437\n",
      "Epoch 250/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.2844\n",
      "Epoch 251/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.2594\n",
      "Epoch 252/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.0812\n",
      "Epoch 253/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.4875\n",
      "Epoch 254/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.0844\n",
      "Epoch 255/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.3187\n",
      "Epoch 256/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.4250\n",
      "Epoch 257/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.0094\n",
      "Epoch 258/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 259/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.1594\n",
      "Epoch 260/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.2250\n",
      "Epoch 261/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.1219\n",
      "Epoch 262/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.3250\n",
      "Epoch 263/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.3125\n",
      "Epoch 264/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.0000e+00\n",
      "Epoch 265/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.4031\n",
      "Epoch 266/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.0938\n",
      "Epoch 267/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.2719\n",
      "Epoch 268/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.1562\n",
      "Epoch 269/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.2438\n",
      "Epoch 270/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.1281\n",
      "Epoch 271/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.4563\n",
      "Epoch 272/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.0344\n",
      "Epoch 273/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.3688\n",
      "Epoch 274/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4000\n",
      "Epoch 275/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.1844\n",
      "Epoch 276/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.1281\n",
      "Epoch 277/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4750\n",
      "Epoch 278/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.2375\n",
      "Epoch 279/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.0844\n",
      "Epoch 280/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.4875\n",
      "Epoch 281/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.2844\n",
      "Epoch 282/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.0656\n",
      "Epoch 283/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 284/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.3531\n",
      "Epoch 285/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2513 - accuracy: 0.1063\n",
      "Epoch 286/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.3031\n",
      "Epoch 287/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.1406\n",
      "Epoch 288/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.2406\n",
      "Epoch 289/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.4250\n",
      "Epoch 290/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.0000e+00\n",
      "Epoch 291/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.3281\n",
      "Epoch 292/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.1031\n",
      "Epoch 293/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.3469\n",
      "Epoch 294/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.2469\n",
      "Epoch 295/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.0000e+00\n",
      "Epoch 296/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.3750\n",
      "Epoch 297/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.2750\n",
      "Epoch 298/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.3250\n",
      "Epoch 299/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.1813\n",
      "Epoch 300/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.2000\n",
      "Epoch 301/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.3719\n",
      "Epoch 302/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.0562\n",
      "Epoch 303/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.4750\n",
      "Epoch 304/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.0500\n",
      "Epoch 305/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.1344\n",
      "Epoch 306/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.2344\n",
      "Epoch 307/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.2750\n",
      "Epoch 308/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.1437\n",
      "Epoch 309/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4875\n",
      "Epoch 310/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.0875\n",
      "Epoch 311/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 312/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.0500\n",
      "Epoch 313/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2513 - accuracy: 0.3000\n",
      "Epoch 314/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.1688\n",
      "Epoch 315/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.3313\n",
      "Epoch 316/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.1937\n",
      "Epoch 317/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.3531\n",
      "Epoch 318/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.0000e+00\n",
      "Epoch 319/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.3812\n",
      "Epoch 320/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.0688\n",
      "Epoch 321/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.3938\n",
      "Epoch 322/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.1781\n",
      "Epoch 323/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.4125\n",
      "Epoch 324/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.0000e+00\n",
      "Epoch 325/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.3906\n",
      "Epoch 326/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.4875\n",
      "Epoch 327/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.1156\n",
      "Epoch 328/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.2719\n",
      "Epoch 329/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.3094\n",
      "Epoch 330/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.0781\n",
      "Epoch 331/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.1719\n",
      "Epoch 332/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.3938\n",
      "Epoch 333/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.0188\n",
      "Epoch 334/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.4875\n",
      "Epoch 335/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.0656\n",
      "Epoch 336/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.3531\n",
      "Epoch 337/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2506 - accuracy: 0.0125\n",
      "Epoch 338/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.3812\n",
      "Epoch 339/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.0000e+00\n",
      "Epoch 340/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.4688\n",
      "Epoch 341/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.3156\n",
      "Epoch 342/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.2000\n",
      "Epoch 343/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.2562\n",
      "Epoch 344/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.2719\n",
      "Epoch 345/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.1844\n",
      "Epoch 346/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.0812\n",
      "Epoch 347/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 348/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.0938\n",
      "Epoch 349/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.4656\n",
      "Epoch 350/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.0219\n",
      "Epoch 351/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.4875\n",
      "Epoch 352/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.1000\n",
      "Epoch 353/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.2625\n",
      "Epoch 354/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.1656\n",
      "Epoch 355/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 356/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.0000e+00\n",
      "Epoch 357/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.1719\n",
      "Epoch 358/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.3344\n",
      "Epoch 359/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.0500\n",
      "Epoch 360/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.3844\n",
      "Epoch 361/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.2594\n",
      "Epoch 362/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.0156\n",
      "Epoch 363/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.2719\n",
      "Epoch 364/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.0312\n",
      "Epoch 365/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.2375\n",
      "Epoch 366/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.1875\n",
      "Epoch 367/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.1719\n",
      "Epoch 368/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.3500\n",
      "Epoch 369/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.0688\n",
      "Epoch 370/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4875\n",
      "Epoch 371/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2514 - accuracy: 0.2156\n",
      "Epoch 372/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.1156\n",
      "Epoch 373/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.4688\n",
      "Epoch 374/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.0781\n",
      "Epoch 375/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.2969\n",
      "Epoch 376/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.3562\n",
      "Epoch 377/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.1437\n",
      "Epoch 378/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.1750\n",
      "Epoch 379/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.1437\n",
      "Epoch 380/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.3500\n",
      "Epoch 381/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.3438\n",
      "Epoch 382/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2507 - accuracy: 0.1875\n",
      "Epoch 383/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.0375\n",
      "Epoch 384/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.4750\n",
      "Epoch 385/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.0000e+00\n",
      "Epoch 386/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.4000\n",
      "Epoch 387/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.1813\n",
      "Epoch 388/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.0906\n",
      "Epoch 389/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.1844\n",
      "Epoch 390/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.4625\n",
      "Epoch 391/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.0000e+00\n",
      "Epoch 392/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.3906\n",
      "Epoch 393/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.0969\n",
      "Epoch 394/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.4875\n",
      "Epoch 395/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.1781\n",
      "Epoch 396/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.1219\n",
      "Epoch 397/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4875\n",
      "Epoch 398/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.0750\n",
      "Epoch 399/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2513 - accuracy: 0.1719\n",
      "Epoch 400/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.4406\n",
      "Epoch 401/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.1469\n",
      "Epoch 402/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.1250\n",
      "Epoch 403/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.0125\n",
      "Epoch 404/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 405/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.1406\n",
      "Epoch 406/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.4875\n",
      "Epoch 407/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.0219\n",
      "Epoch 408/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.1437\n",
      "Epoch 409/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4250\n",
      "Epoch 410/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.0000e+00\n",
      "Epoch 411/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.3781\n",
      "Epoch 412/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.4563\n",
      "Epoch 413/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.0156\n",
      "Epoch 414/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4125\n",
      "Epoch 415/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.4563\n",
      "Epoch 416/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.0000e+00\n",
      "Epoch 417/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.3156\n",
      "Epoch 418/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2505 - accuracy: 0.4094\n",
      "Epoch 419/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.1969\n",
      "Epoch 420/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.0000e+00\n",
      "Epoch 421/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.3656\n",
      "Epoch 422/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.1781\n",
      "Epoch 423/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.1750\n",
      "Epoch 424/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.0594\n",
      "Epoch 425/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.4875\n",
      "Epoch 426/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.0562\n",
      "Epoch 427/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 428/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.1750\n",
      "Epoch 429/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.0000e+00\n",
      "Epoch 430/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.2750\n",
      "Epoch 431/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.4875\n",
      "Epoch 432/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.0688\n",
      "Epoch 433/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4062\n",
      "Epoch 434/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.2500\n",
      "Epoch 435/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.1844\n",
      "Epoch 436/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.3625\n",
      "Epoch 437/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.3344\n",
      "Epoch 438/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2513 - accuracy: 0.1125\n",
      "Epoch 439/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.0531\n",
      "Epoch 440/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.3063\n",
      "Epoch 441/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.3594\n",
      "Epoch 442/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.1281\n",
      "Epoch 443/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.0938\n",
      "Epoch 444/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.2188\n",
      "Epoch 445/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.1031\n",
      "Epoch 446/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.4875\n",
      "Epoch 447/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.0219\n",
      "Epoch 448/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.2062\n",
      "Epoch 449/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.2000\n",
      "Epoch 450/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.2531\n",
      "Epoch 451/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.3219\n",
      "Epoch 452/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.0688\n",
      "Epoch 453/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.4375\n",
      "Epoch 454/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.0000e+00\n",
      "Epoch 455/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.2219\n",
      "Epoch 456/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.3812\n",
      "Epoch 457/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2511 - accuracy: 0.1406\n",
      "Epoch 458/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.3656\n",
      "Epoch 459/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.2781\n",
      "Epoch 460/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.1031\n",
      "Epoch 461/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2518 - accuracy: 0.3906\n",
      "Epoch 462/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.0000e+00\n",
      "Epoch 463/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.3219\n",
      "Epoch 464/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.2313\n",
      "Epoch 465/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.0875\n",
      "Epoch 466/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.1094\n",
      "Epoch 467/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.4875\n",
      "Epoch 468/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.1531\n",
      "Epoch 469/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.1312\n",
      "Epoch 470/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.1250\n",
      "Epoch 471/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.4125\n",
      "Epoch 472/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.1250\n",
      "Epoch 473/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.4437\n",
      "Epoch 474/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.0406\n",
      "Epoch 475/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2505 - accuracy: 0.4875\n",
      "Epoch 476/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.0344\n",
      "Epoch 477/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.2000\n",
      "Epoch 478/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.3844\n",
      "Epoch 479/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.0000e+00\n",
      "Epoch 480/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4625\n",
      "Epoch 481/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.4469\n",
      "Epoch 482/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.0000e+00\n",
      "Epoch 483/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.1562\n",
      "Epoch 484/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.3844\n",
      "Epoch 485/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.0000e+00\n",
      "Epoch 486/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.2531\n",
      "Epoch 487/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 488/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.0625\n",
      "Epoch 489/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.1719\n",
      "Epoch 490/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 491/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.0531\n",
      "Epoch 492/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2511 - accuracy: 0.4313\n",
      "Epoch 493/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2503 - accuracy: 0.1094\n",
      "Epoch 494/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.1437\n",
      "Epoch 495/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.2937\n",
      "Epoch 496/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.3375\n",
      "Epoch 497/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.0625\n",
      "Epoch 498/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.4187\n",
      "Epoch 499/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.1187\n",
      "Epoch 500/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.3562\n",
      "Epoch 501/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.1875\n",
      "Epoch 502/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.0594\n",
      "Epoch 503/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.2531\n",
      "Epoch 504/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.3719\n",
      "Epoch 505/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2518 - accuracy: 0.0000e+00\n",
      "Epoch 506/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2518 - accuracy: 0.4750\n",
      "Epoch 507/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.0406\n",
      "Epoch 508/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.4219\n",
      "Epoch 509/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.3125\n",
      "Epoch 510/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.2344\n",
      "Epoch 511/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.2094\n",
      "Epoch 512/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.1813\n",
      "Epoch 513/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.3219\n",
      "Epoch 514/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4031\n",
      "Epoch 515/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.0156\n",
      "Epoch 516/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.3594\n",
      "Epoch 517/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.2594\n",
      "Epoch 518/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.1844\n",
      "Epoch 519/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2508 - accuracy: 0.2656\n",
      "Epoch 520/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.3219\n",
      "Epoch 521/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.2344\n",
      "Epoch 522/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.0875\n",
      "Epoch 523/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 524/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.0000e+00\n",
      "Epoch 525/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.0656\n",
      "Epoch 526/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2517 - accuracy: 0.3938\n",
      "Epoch 527/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.0000e+00\n",
      "Epoch 528/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.0000e+00\n",
      "Epoch 529/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.3750\n",
      "Epoch 530/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.2719\n",
      "Epoch 531/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.3438\n",
      "Epoch 532/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.0000e+00\n",
      "Epoch 533/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.3000\n",
      "Epoch 534/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.4875\n",
      "Epoch 535/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2505 - accuracy: 0.2000\n",
      "Epoch 536/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.2281\n",
      "Epoch 537/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.0875\n",
      "Epoch 538/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.0969\n",
      "Epoch 539/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.3094\n",
      "Epoch 540/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.2969\n",
      "Epoch 541/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.0562\n",
      "Epoch 542/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.3500\n",
      "Epoch 543/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.0406\n",
      "Epoch 544/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.4875\n",
      "Epoch 545/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.0375\n",
      "Epoch 546/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.4531\n",
      "Epoch 547/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.0437\n",
      "Epoch 548/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.3313\n",
      "Epoch 549/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.4031\n",
      "Epoch 550/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.1406\n",
      "Epoch 551/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.4875\n",
      "Epoch 552/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.0094\n",
      "Epoch 553/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.1594\n",
      "Epoch 554/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.3906\n",
      "Epoch 555/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.0312\n",
      "Epoch 556/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.4750\n",
      "Epoch 557/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.1969\n",
      "Epoch 558/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 559/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.1781\n",
      "Epoch 560/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.3313\n",
      "Epoch 561/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.3750\n",
      "Epoch 562/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.5312\n",
      "Epoch 563/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.0844\n",
      "Epoch 564/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.4875\n",
      "Epoch 565/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.2781\n",
      "Epoch 566/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.0969\n",
      "Epoch 567/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 568/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.1281\n",
      "Epoch 569/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4875\n",
      "Epoch 570/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.2625\n",
      "Epoch 571/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.2812\n",
      "Epoch 572/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.3562\n",
      "Epoch 573/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.1562\n",
      "Epoch 574/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.4719\n",
      "Epoch 575/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.1813\n",
      "Epoch 576/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.3438\n",
      "Epoch 577/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.3969\n",
      "Epoch 578/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.2781\n",
      "Epoch 579/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.4250\n",
      "Epoch 580/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.3031\n",
      "Epoch 581/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2508 - accuracy: 0.3031\n",
      "Epoch 582/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.0000e+00\n",
      "Epoch 583/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.4031\n",
      "Epoch 584/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.0000e+00\n",
      "Epoch 585/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.3406\n",
      "Epoch 586/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.2937\n",
      "Epoch 587/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.3625\n",
      "Epoch 588/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.1375\n",
      "Epoch 589/770\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 590/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.4875\n",
      "Epoch 591/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.2594\n",
      "Epoch 592/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.2812\n",
      "Epoch 593/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 594/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4531\n",
      "Epoch 595/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.1344\n",
      "Epoch 596/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.3906\n",
      "Epoch 597/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 598/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.4875\n",
      "Epoch 599/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 600/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 601/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.4000\n",
      "Epoch 602/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.0312\n",
      "Epoch 603/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.4875\n",
      "Epoch 604/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.1094\n",
      "Epoch 605/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.2531\n",
      "Epoch 606/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2506 - accuracy: 0.4125\n",
      "Epoch 607/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.4875\n",
      "Epoch 608/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.1094\n",
      "Epoch 609/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 610/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 611/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.3063\n",
      "Epoch 612/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.2719\n",
      "Epoch 613/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2512 - accuracy: 0.4875\n",
      "Epoch 614/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.1594\n",
      "Epoch 615/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.3344\n",
      "Epoch 616/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.4750\n",
      "Epoch 617/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.0000e+00\n",
      "Epoch 618/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.3938\n",
      "Epoch 619/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.1906\n",
      "Epoch 620/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.3594\n",
      "Epoch 621/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.3344\n",
      "Epoch 622/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.3375\n",
      "Epoch 623/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.4875\n",
      "Epoch 624/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.1281\n",
      "Epoch 625/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.4875\n",
      "Epoch 626/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 627/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 628/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.4875\n",
      "Epoch 629/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 630/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 631/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 632/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 633/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4875\n",
      "Epoch 634/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.4875\n",
      "Epoch 635/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.4875\n",
      "Epoch 636/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.3812\n",
      "Epoch 637/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.3187\n",
      "Epoch 638/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4875\n",
      "Epoch 639/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 640/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.4688\n",
      "Epoch 641/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.0000e+00\n",
      "Epoch 642/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.2719\n",
      "Epoch 643/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2523 - accuracy: 0.3438\n",
      "Epoch 644/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.4531\n",
      "Epoch 645/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.4875\n",
      "Epoch 646/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.2188\n",
      "Epoch 647/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.3906\n",
      "Epoch 648/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.2625\n",
      "Epoch 649/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2512 - accuracy: 0.0938\n",
      "Epoch 650/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.4875\n",
      "Epoch 651/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 652/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 653/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.0531\n",
      "Epoch 654/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.3000\n",
      "Epoch 655/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 656/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2512 - accuracy: 0.4875\n",
      "Epoch 657/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 658/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.2156\n",
      "Epoch 659/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2521 - accuracy: 0.4688\n",
      "Epoch 660/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.3688\n",
      "Epoch 661/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 662/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2508 - accuracy: 0.4875\n",
      "Epoch 663/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.4875\n",
      "Epoch 664/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2511 - accuracy: 0.4875\n",
      "Epoch 665/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 666/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.4875\n",
      "Epoch 667/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.4875\n",
      "Epoch 668/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 669/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.4875\n",
      "Epoch 670/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 671/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.4875\n",
      "Epoch 672/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.0906\n",
      "Epoch 673/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2505 - accuracy: 0.2969\n",
      "Epoch 674/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.3719\n",
      "Epoch 675/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.3750\n",
      "Epoch 676/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.3031\n",
      "Epoch 677/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.3625\n",
      "Epoch 678/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.4875\n",
      "Epoch 679/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.4875\n",
      "Epoch 680/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.4875\n",
      "Epoch 681/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 682/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.4875\n",
      "Epoch 683/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.4875\n",
      "Epoch 684/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.4875\n",
      "Epoch 685/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.4875\n",
      "Epoch 686/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 687/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 688/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.4875\n",
      "Epoch 689/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.4875\n",
      "Epoch 690/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.4875\n",
      "Epoch 691/770\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 692/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.4875\n",
      "Epoch 693/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2521 - accuracy: 0.4875\n",
      "Epoch 694/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.0938\n",
      "Epoch 695/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.4875\n",
      "Epoch 696/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 697/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2508 - accuracy: 0.4875\n",
      "Epoch 698/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.4875\n",
      "Epoch 699/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 700/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2511 - accuracy: 0.4875\n",
      "Epoch 701/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.4875\n",
      "Epoch 702/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.4875\n",
      "Epoch 703/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 704/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.4875\n",
      "Epoch 705/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.4875\n",
      "Epoch 706/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 707/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 708/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.4875\n",
      "Epoch 709/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 710/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 711/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.4875\n",
      "Epoch 712/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.4875\n",
      "Epoch 713/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 714/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2513 - accuracy: 0.4875\n",
      "Epoch 715/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 716/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 717/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.4875\n",
      "Epoch 718/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 719/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.4875\n",
      "Epoch 720/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.4875\n",
      "Epoch 721/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.4875\n",
      "Epoch 722/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 723/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.4875\n",
      "Epoch 724/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 725/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4875\n",
      "Epoch 726/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 727/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.4875\n",
      "Epoch 728/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 729/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 730/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4875\n",
      "Epoch 731/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.4875\n",
      "Epoch 732/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.4875\n",
      "Epoch 733/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.4875\n",
      "Epoch 734/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.4875\n",
      "Epoch 735/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.4875\n",
      "Epoch 736/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.4875\n",
      "Epoch 737/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 738/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 739/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.4875\n",
      "Epoch 740/770\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 741/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 742/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.4875\n",
      "Epoch 743/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.4875\n",
      "Epoch 744/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 745/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.4875\n",
      "Epoch 746/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.4875\n",
      "Epoch 747/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4875\n",
      "Epoch 748/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 749/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 750/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.4875\n",
      "Epoch 751/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.4875\n",
      "Epoch 752/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.4875\n",
      "Epoch 753/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 754/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.4875\n",
      "Epoch 755/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.4875\n",
      "Epoch 756/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 757/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.4875\n",
      "Epoch 758/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 759/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.4875\n",
      "Epoch 760/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 761/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 762/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.4875\n",
      "Epoch 763/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 764/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.4875\n",
      "Epoch 765/770\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.4875\n",
      "Epoch 766/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.4875\n",
      "Epoch 767/770\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 768/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.4875\n",
      "Epoch 769/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4875\n",
      "Epoch 770/770\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.4875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26809ec0150>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=10, epochs=770)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 5ms/step - loss: 0.2513 - accuracy: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25127464532852173, 0.550000011920929]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are different than what I saw in the tensorflowplayground. I wonder if it depends on some parameters that I set differently (like the optimizer...)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
