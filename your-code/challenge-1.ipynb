{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Tic Tac Toe\n",
    "\n",
    "In this lab you will perform deep learning analysis on a dataset of playing [Tic Tac Toe](https://en.wikipedia.org/wiki/Tic-tac-toe).\n",
    "\n",
    "There are 9 grids in Tic Tac Toe that are coded as the following picture shows:\n",
    "\n",
    "![Tic Tac Toe Grids](tttboard.jpg)\n",
    "\n",
    "In the first 9 columns of the dataset you can find which marks (`x` or `o`) exist in the grids. If there is no mark in a certain grid, it is labeled as `b`. The last column is `class` which tells you whether Player X (who always moves first in Tic Tac Toe) wins in this configuration. Note that when `class` has the value `False`, it means either Player O wins the game or it ends up as a draw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps suggested below to conduct a neural network analysis using Tensorflow and Keras. You will build a deep learning model to predict whether Player X wins the game or not.\n",
    "\n",
    "## Step 1: Data Engineering\n",
    "\n",
    "This dataset is almost in the ready-to-use state so you do not need to worry about missing values and so on. Still, some simple data engineering is needed.\n",
    "\n",
    "1. Read `tic-tac-toe.csv` into a dataframe.\n",
    "1. Inspect the dataset. Determine if the dataset is reliable by eyeballing the data.\n",
    "1. Convert the categorical values to numeric in all columns.\n",
    "1. Separate the inputs and output.\n",
    "1. Normalize the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zluca\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read `tic-tac-toe.csv` into a dataframe.\n",
    "tic_tac_toe = pd.read_csv('tic-tac-toe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(958, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TL TM TR ML MM MR BL BM BR  class\n",
       "0  x  x  x  x  o  o  x  o  o   True\n",
       "1  x  x  x  x  o  o  o  x  o   True\n",
       "2  x  x  x  x  o  o  o  o  x   True\n",
       "3  x  x  x  x  o  o  o  b  b   True\n",
       "4  x  x  x  x  o  o  b  o  b   True\n",
       "5  x  x  x  x  o  o  b  b  o   True\n",
       "6  x  x  x  x  o  b  o  o  b   True\n",
       "7  x  x  x  x  o  b  o  b  o   True\n",
       "8  x  x  x  x  o  b  b  o  o   True\n",
       "9  x  x  x  x  b  o  o  o  b   True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Inspect the dataset. Determine if the dataset is reliable by eyeballing the data.\n",
    "print(tic_tac_toe.shape)\n",
    "tic_tac_toe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TL       object\n",
       "TM       object\n",
       "TR       object\n",
       "ML       object\n",
       "MM       object\n",
       "MR       object\n",
       "BL       object\n",
       "BM       object\n",
       "BR       object\n",
       "class      bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examining all data types (they should be categorical, but they need to be numerical to be fed to the model).\n",
    "tic_tac_toe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert the categorical values to numeric in all columns.\n",
    "# I can use the LabelEncoder from scikit learn or I can use the pd.get_dummies in pandas.\n",
    "# I will try both methods, just to see if there are differencies in results.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "tic_tac_toe_encoded = tic_tac_toe.apply(label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic_tac_toe_dummies = pd.get_dummies(tic_tac_toe, columns=tic_tac_toe.columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(958, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL_o</th>\n",
       "      <th>TL_x</th>\n",
       "      <th>TM_o</th>\n",
       "      <th>TM_x</th>\n",
       "      <th>TR_o</th>\n",
       "      <th>TR_x</th>\n",
       "      <th>ML_o</th>\n",
       "      <th>ML_x</th>\n",
       "      <th>MM_o</th>\n",
       "      <th>MM_x</th>\n",
       "      <th>MR_o</th>\n",
       "      <th>MR_x</th>\n",
       "      <th>BL_o</th>\n",
       "      <th>BL_x</th>\n",
       "      <th>BM_o</th>\n",
       "      <th>BM_x</th>\n",
       "      <th>BR_o</th>\n",
       "      <th>BR_x</th>\n",
       "      <th>class_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TL_o  TL_x  TM_o  TM_x  TR_o  TR_x  ML_o  ML_x  MM_o  MM_x  MR_o  MR_x  \\\n",
       "0       0     1     0     1     0     1     0     1     1     0     1     0   \n",
       "1       0     1     0     1     0     1     0     1     1     0     1     0   \n",
       "2       0     1     0     1     0     1     0     1     1     0     1     0   \n",
       "3       0     1     0     1     0     1     0     1     1     0     1     0   \n",
       "4       0     1     0     1     0     1     0     1     1     0     1     0   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "953     1     0     0     1     0     1     0     1     1     0     1     0   \n",
       "954     1     0     0     1     1     0     0     1     0     1     1     0   \n",
       "955     1     0     0     1     1     0     0     1     1     0     0     1   \n",
       "956     1     0     0     1     1     0     1     0     0     1     0     1   \n",
       "957     1     0     1     0     0     1     0     1     0     1     1     0   \n",
       "\n",
       "     BL_o  BL_x  BM_o  BM_x  BR_o  BR_x  class_True  \n",
       "0       0     1     1     0     1     0           1  \n",
       "1       1     0     0     1     1     0           1  \n",
       "2       1     0     1     0     0     1           1  \n",
       "3       1     0     0     0     0     0           1  \n",
       "4       0     0     1     0     0     0           1  \n",
       "..    ...   ...   ...   ...   ...   ...         ...  \n",
       "953     1     0     0     1     0     1           0  \n",
       "954     0     1     1     0     0     1           0  \n",
       "955     0     1     1     0     0     1           0  \n",
       "956     0     1     1     0     0     1           0  \n",
       "957     1     0     0     1     0     1           0  \n",
       "\n",
       "[958 rows x 19 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tic_tac_toe_dummies.shape)\n",
    "tic_tac_toe_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(958, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TL  TM  TR  ML  MM  MR  BL  BM  BR  class\n",
       "0     2   2   2   2   1   1   2   1   1      1\n",
       "1     2   2   2   2   1   1   1   2   1      1\n",
       "2     2   2   2   2   1   1   1   1   2      1\n",
       "3     2   2   2   2   1   1   1   0   0      1\n",
       "4     2   2   2   2   1   1   0   1   0      1\n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
       "953   1   2   2   2   1   1   1   2   2      0\n",
       "954   1   2   1   2   2   1   2   1   2      0\n",
       "955   1   2   1   2   1   2   2   1   2      0\n",
       "956   1   2   1   1   2   2   2   1   2      0\n",
       "957   1   1   2   2   2   1   1   2   2      0\n",
       "\n",
       "[958 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tic_tac_toe_encoded.shape)\n",
    "tic_tac_toe_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Separate the inputs and output.\n",
    "X_dummies = tic_tac_toe_dummies.drop('class_True', axis=1)\n",
    "y_dummies = tic_tac_toe_dummies['class_True']\n",
    "\n",
    "X_encoded = tic_tac_toe_encoded.drop('class', axis=1)\n",
    "y_encoded = tic_tac_toe_encoded['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Normalize the input data.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_encoded_scaled = scaler.fit_transform(X_encoded)\n",
    "X_dummies_scaled = scaler.fit_transform(X_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(958, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.00322257,  1.08495342,  1.00322257, ...,  1.00322257,\n",
       "        -0.16731812, -0.28682739],\n",
       "       [ 1.00322257,  1.08495342,  1.00322257, ..., -0.28682739,\n",
       "         1.08495342, -0.28682739],\n",
       "       [ 1.00322257,  1.08495342,  1.00322257, ..., -0.28682739,\n",
       "        -0.16731812,  1.00322257],\n",
       "       ...,\n",
       "       [-0.28682739,  1.08495342, -0.28682739, ...,  1.00322257,\n",
       "        -0.16731812,  1.00322257],\n",
       "       [-0.28682739,  1.08495342, -0.28682739, ...,  1.00322257,\n",
       "        -0.16731812,  1.00322257],\n",
       "       [-0.28682739, -0.16731812,  1.00322257, ..., -0.28682739,\n",
       "         1.08495342,  1.00322257]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_encoded_scaled.shape)\n",
    "X_encoded_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(958, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.73329442,  1.13660285, -0.72489841, ..., -0.80729433,\n",
       "         1.36370873, -0.8798148 ],\n",
       "       [-0.73329442,  1.13660285, -0.72489841, ...,  1.23870559,\n",
       "         1.36370873, -0.8798148 ],\n",
       "       [-0.73329442,  1.13660285, -0.72489841, ..., -0.80729433,\n",
       "        -0.73329442,  1.13660285],\n",
       "       ...,\n",
       "       [ 1.36370873, -0.8798148 , -0.72489841, ..., -0.80729433,\n",
       "        -0.73329442,  1.13660285],\n",
       "       [ 1.36370873, -0.8798148 , -0.72489841, ..., -0.80729433,\n",
       "        -0.73329442,  1.13660285],\n",
       "       [ 1.36370873, -0.8798148 ,  1.37950364, ...,  1.23870559,\n",
       "        -0.73329442,  1.13660285]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_dummies_scaled.shape)\n",
    "X_dummies_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build Neural Network\n",
    "\n",
    "To build the neural network, you can refer to your own codes you wrote while following the [Deep Learning with Python, TensorFlow, and Keras tutorial](https://www.youtube.com/watch?v=wQ8BIBpya2k) in the lesson. It's pretty similar to what you will be doing in this lab.\n",
    "\n",
    "1. Split the training and test data.\n",
    "1. Create a `Sequential` model.\n",
    "1. Add several layers to your model. Make sure you use ReLU as the activation function for the middle layers. Use Softmax for the output layer because each output has a single lable and all the label probabilities add up to 1.\n",
    "1. Compile the model using `adam` as the optimizer and `sparse_categorical_crossentropy` as the loss function. For metrics, use `accuracy` for now.\n",
    "1. Fit the training data.\n",
    "1. Evaluate your neural network model with the test data.\n",
    "1. Save your model as `tic-tac-toe.model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split in training in test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded_scaled, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummies, X_test_dummies, y_train_dummies, y_test_dummies = train_test_split(X_dummies_scaled, y_dummies, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zluca\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Create a Sequential model\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Add several layers to your model. \n",
    "# Make sure you use ReLu as activation function for the middle layers. Use Softmax for the output layer.\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zluca\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Compile the model using adam as the optimizer and sparse_categorical_crossentropy as the loss function. For metrics use accuracy.\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zluca\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\zluca\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "24/24 [==============================] - 2s 4ms/step - loss: 1.3556 - accuracy: 0.6175\n",
      "Epoch 2/3\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6932\n",
      "Epoch 3/3\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f15dcc8c50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Fit the training data (on the encoded df with LabelEncoder)\n",
    "model.fit(X_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried to fit the same model to the df that was processed with pd.get_dummies, but I had to modify the model's structure.\n",
    "# I had to specify the input_shape as the number of features we feed to the model (18), to avoid getting a ValueError this time.\n",
    "\n",
    "# Assuming X_train_dummies is your training data after one-hot encoding\n",
    "input_dim = X_train_dummies.shape[1]\n",
    "\n",
    "# Create a Sequential model\n",
    "model2 = tf.keras.models.Sequential()\n",
    "\n",
    "# Add a Dense layer with the correct input shape\n",
    "model2.add(tf.keras.layers.Flatten(input_shape=(input_dim,)))\n",
    "model2.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model2.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model2.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 9)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19082 (74.54 KB)\n",
      "Trainable params: 19082 (74.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 18)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               2432      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20234 (79.04 KB)\n",
      "Trainable params: 20234 (79.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 4ms/step - loss: 1.3778 - accuracy: 0.5627\n",
      "Epoch 2/3\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7298\n",
      "Epoch 3/3\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f15db0ac90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Fit the training data (on the encoded df with pd.get_dummies)\n",
    "model2.fit(X_train_dummies, y_train_dummies, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.7188\n",
      "Validation Loss: 0.5801398754119873\n",
      "Validation Accuracy: 0.71875\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.8073\n",
      "Validation Loss (Model 2): 0.43232178688049316\n",
      "Validation Accuracy (Model 2): 0.8072916865348816\n"
     ]
    }
   ],
   "source": [
    "# 6. Evaluate your neural networks models with the test data.\n",
    "\n",
    "# first model\n",
    "val_loss, val_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Validation Loss:\", val_loss)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# second model\n",
    "val_loss2, val_acc2 = model2.evaluate(X_test_dummies, y_test_dummies)\n",
    "print(\"Validation Loss (Model 2):\", val_loss2)\n",
    "print(\"Validation Accuracy (Model 2):\", val_acc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tic-tac-toe.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tic-tac-toe.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tic_tac_toe,model2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tic_tac_toe,model2\\assets\n"
     ]
    }
   ],
   "source": [
    "# 7. Save your model(s)\n",
    "model.save('tic-tac-toe.model')\n",
    "model2.save('tic_tac_toe,model2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions\n",
    "\n",
    "Now load your saved model and use it to make predictions on a few random rows in the test dataset. Check if the predictions are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zluca\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zluca\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 9)\n",
      "(192, 1)\n"
     ]
    }
   ],
   "source": [
    "# loading the (first) Sequential model\n",
    "model = tf.keras.models.load_model('tic-tac-toe.model')\n",
    "\n",
    "# checking that X_test and y_test have the same number of rows\n",
    "print(pd.DataFrame(X_test).shape)\n",
    "print(pd.DataFrame(y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.286827</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>0.930371</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>1.003223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.286827</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>0.930371</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-0.286827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.286827</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>0.930371</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.286827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>0.930371</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-0.286827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.286827</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.420077</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.286827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-0.286827</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>0.930371</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.286827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.003223</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.420077</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-1.576877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.003223</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-0.420077</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-1.576877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.003223</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-0.420077</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.286827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.003223</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-0.420077</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>1.003223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.286827 -0.167318 -0.286827 -1.419590  0.930371  1.084953  1.003223   \n",
       "1   -0.286827 -1.419590 -1.576877  1.084953  0.930371  1.084953 -1.576877   \n",
       "2   -0.286827  1.084953 -1.576877  1.084953  0.930371 -1.419590 -0.286827   \n",
       "3   -1.576877  1.084953 -0.286827  1.084953  0.930371 -0.167318  1.003223   \n",
       "4   -0.286827 -1.419590  1.003223  1.084953 -0.420077 -1.419590 -1.576877   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "187 -0.286827 -1.419590 -0.286827  1.084953  0.930371  1.084953 -1.576877   \n",
       "188  1.003223 -0.167318  1.003223  1.084953 -0.420077  1.084953 -0.286827   \n",
       "189  1.003223  1.084953  1.003223 -0.167318 -0.420077 -1.419590 -1.576877   \n",
       "190  1.003223  1.084953  1.003223 -0.167318 -0.420077 -1.419590 -1.576877   \n",
       "191  1.003223 -1.419590  1.003223 -0.167318 -0.420077 -0.167318 -1.576877   \n",
       "\n",
       "            7         8  \n",
       "0   -0.167318  1.003223  \n",
       "1   -1.419590 -0.286827  \n",
       "2    1.084953 -0.286827  \n",
       "3   -0.167318 -0.286827  \n",
       "4    1.084953 -0.286827  \n",
       "..        ...       ...  \n",
       "187  1.084953 -0.286827  \n",
       "188 -0.167318 -1.576877  \n",
       "189 -1.419590 -1.576877  \n",
       "190  1.084953 -0.286827  \n",
       "191 -1.419590  1.003223  \n",
       "\n",
       "[192 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df = pd.DataFrame(X_test)\n",
    "X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class\n",
       "0        0\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "..     ...\n",
       "187      1\n",
       "188      0\n",
       "189      1\n",
       "190      1\n",
       "191      0\n",
       "\n",
       "[192 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_test_df.reset_index(inplace=True)\n",
    "y_test_df.drop(columns={'index'}, inplace=True)\n",
    "y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.286827</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>0.930371</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.286827</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>0.930371</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.286827</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>0.930371</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>0.930371</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.286827</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.420077</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-0.286827</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>0.930371</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.003223</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.420077</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.003223</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-0.420077</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.003223</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-0.420077</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>1.084953</td>\n",
       "      <td>-0.286827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.003223</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-0.420077</td>\n",
       "      <td>-0.167318</td>\n",
       "      <td>-1.576877</td>\n",
       "      <td>-1.419590</td>\n",
       "      <td>1.003223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.286827 -0.167318 -0.286827 -1.419590  0.930371  1.084953  1.003223   \n",
       "1   -0.286827 -1.419590 -1.576877  1.084953  0.930371  1.084953 -1.576877   \n",
       "2   -0.286827  1.084953 -1.576877  1.084953  0.930371 -1.419590 -0.286827   \n",
       "3   -1.576877  1.084953 -0.286827  1.084953  0.930371 -0.167318  1.003223   \n",
       "4   -0.286827 -1.419590  1.003223  1.084953 -0.420077 -1.419590 -1.576877   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "187 -0.286827 -1.419590 -0.286827  1.084953  0.930371  1.084953 -1.576877   \n",
       "188  1.003223 -0.167318  1.003223  1.084953 -0.420077  1.084953 -0.286827   \n",
       "189  1.003223  1.084953  1.003223 -0.167318 -0.420077 -1.419590 -1.576877   \n",
       "190  1.003223  1.084953  1.003223 -0.167318 -0.420077 -1.419590 -1.576877   \n",
       "191  1.003223 -1.419590  1.003223 -0.167318 -0.420077 -0.167318 -1.576877   \n",
       "\n",
       "            7         8  class  \n",
       "0   -0.167318  1.003223      0  \n",
       "1   -1.419590 -0.286827      1  \n",
       "2    1.084953 -0.286827      1  \n",
       "3   -0.167318 -0.286827      0  \n",
       "4    1.084953 -0.286827      0  \n",
       "..        ...       ...    ...  \n",
       "187  1.084953 -0.286827      1  \n",
       "188 -0.167318 -1.576877      0  \n",
       "189 -1.419590 -1.576877      1  \n",
       "190  1.084953 -0.286827      1  \n",
       "191 -1.419590  1.003223      0  \n",
       "\n",
       "[192 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df =  pd.concat([X_test_df, y_test_df], axis=1)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 333ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.67668417e-01, 8.30851316e-01, 2.09985272e-04, 8.64769463e-05,\n",
       "        4.39906900e-04, 3.64612701e-04, 7.95956075e-05, 1.19791672e-04,\n",
       "        5.74968471e-05, 1.22450379e-04],\n",
       "       [5.62361240e-01, 4.20086294e-01, 2.76552048e-03, 1.72342174e-03,\n",
       "        2.42862757e-03, 3.69556784e-03, 1.89471093e-03, 2.15435633e-03,\n",
       "        1.06723665e-03, 1.82290620e-03],\n",
       "       [4.49074119e-01, 5.44490099e-01, 9.16596036e-04, 3.78056604e-04,\n",
       "        1.24565908e-03, 1.53283589e-03, 6.01168547e-04, 4.42489545e-04,\n",
       "        4.54024965e-04, 8.65007227e-04],\n",
       "       [6.83746576e-01, 3.02643418e-01, 2.47412687e-03, 1.13034155e-03,\n",
       "        2.45129014e-03, 2.69007380e-03, 1.41021586e-03, 1.45419291e-03,\n",
       "        7.78365938e-04, 1.22147985e-03],\n",
       "       [2.98135370e-01, 6.97373152e-01, 7.18695985e-04, 4.12383670e-04,\n",
       "        8.78392602e-04, 9.11885407e-04, 4.96585097e-04, 4.07530897e-04,\n",
       "        2.44884694e-04, 4.21053788e-04],\n",
       "       [3.35233867e-01, 6.61323190e-01, 4.32937901e-04, 2.61046487e-04,\n",
       "        9.33147210e-04, 7.90805614e-04, 2.64176517e-04, 2.80399283e-04,\n",
       "        2.25576558e-04, 2.54909188e-04],\n",
       "       [2.56702513e-01, 7.40816355e-01, 3.54493735e-04, 2.01563031e-04,\n",
       "        5.27240976e-04, 6.90606306e-04, 1.89152590e-04, 1.70128507e-04,\n",
       "        1.79075156e-04, 1.68862360e-04],\n",
       "       [5.18926799e-01, 4.54711616e-01, 4.33205906e-03, 2.35747267e-03,\n",
       "        4.37042629e-03, 5.04282815e-03, 2.97419261e-03, 3.00752977e-03,\n",
       "        1.75135024e-03, 2.52571004e-03],\n",
       "       [5.82681358e-01, 4.15278435e-01, 4.28880448e-04, 7.64507276e-05,\n",
       "        4.82710893e-04, 4.38815594e-04, 1.34340502e-04, 1.50447915e-04,\n",
       "        9.63705388e-05, 2.32345032e-04],\n",
       "       [2.66773373e-01, 7.32096195e-01, 2.22126109e-04, 4.59313924e-05,\n",
       "        3.22949578e-04, 2.34666557e-04, 6.45943801e-05, 6.23645465e-05,\n",
       "        7.46753212e-05, 1.03030718e-04],\n",
       "       [2.19525576e-01, 7.77195156e-01, 5.45018702e-04, 2.10614133e-04,\n",
       "        8.58881278e-04, 7.83822383e-04, 1.83761556e-04, 2.40315465e-04,\n",
       "        1.70083484e-04, 2.86791270e-04],\n",
       "       [4.79956120e-01, 5.04274249e-01, 2.52687512e-03, 1.39324483e-03,\n",
       "        3.60416691e-03, 3.04842507e-03, 1.38396386e-03, 1.22710376e-03,\n",
       "        1.17715856e-03, 1.40865892e-03],\n",
       "       [2.87398338e-01, 7.02899098e-01, 1.25475822e-03, 5.89453557e-04,\n",
       "        3.18243448e-03, 1.66973204e-03, 7.72089872e-04, 7.72634230e-04,\n",
       "        5.24055446e-04, 9.37399454e-04],\n",
       "       [6.94961369e-01, 3.01167816e-01, 5.48382231e-04, 2.94489000e-04,\n",
       "        6.96053437e-04, 8.64471949e-04, 3.80734011e-04, 2.95373175e-04,\n",
       "        1.40307864e-04, 6.51000824e-04],\n",
       "       [2.91904867e-01, 7.05342531e-01, 4.05084458e-04, 2.40238645e-04,\n",
       "        7.19901582e-04, 5.02655748e-04, 2.45235919e-04, 2.44952389e-04,\n",
       "        1.84203323e-04, 2.10394894e-04],\n",
       "       [3.42130840e-01, 6.56324506e-01, 1.75642184e-04, 1.64301964e-04,\n",
       "        3.13438446e-04, 3.66636639e-04, 1.49775515e-04, 1.46882943e-04,\n",
       "        1.05273371e-04, 1.22794605e-04],\n",
       "       [3.61930132e-01, 6.36154771e-01, 2.58820539e-04, 1.37164840e-04,\n",
       "        5.45366318e-04, 3.73234594e-04, 1.48170177e-04, 1.37200681e-04,\n",
       "        1.18691576e-04, 1.96344336e-04],\n",
       "       [3.77402246e-01, 6.17834628e-01, 5.69088734e-04, 4.07042942e-04,\n",
       "        1.13920751e-03, 9.34662938e-04, 4.94707376e-04, 3.70846421e-04,\n",
       "        3.30062612e-04, 5.17550041e-04],\n",
       "       [2.10199982e-01, 7.87457824e-01, 3.97915312e-04, 2.20617454e-04,\n",
       "        4.34133952e-04, 5.91896998e-04, 2.02240219e-04, 1.91361090e-04,\n",
       "        1.09597830e-04, 1.94397566e-04],\n",
       "       [2.04689741e-01, 7.90792942e-01, 6.89404726e-04, 3.38950864e-04,\n",
       "        9.01579799e-04, 1.06838520e-03, 4.09776549e-04, 4.72866668e-04,\n",
       "        2.12507293e-04, 4.23852674e-04],\n",
       "       [5.33780038e-01, 4.34196740e-01, 4.78568766e-03, 2.95032305e-03,\n",
       "        5.14799030e-03, 5.68703050e-03, 4.19787830e-03, 3.45868641e-03,\n",
       "        2.16909801e-03, 3.62663949e-03],\n",
       "       [6.66922092e-01, 3.21429074e-01, 1.73740601e-03, 8.12389422e-04,\n",
       "        1.55946997e-03, 2.33072857e-03, 1.47730892e-03, 1.31655787e-03,\n",
       "        8.85263958e-04, 1.52974238e-03],\n",
       "       [2.38035828e-01, 7.61064768e-01, 1.53291141e-04, 5.92987490e-05,\n",
       "        2.03020842e-04, 2.26552438e-04, 6.45950349e-05, 7.79648617e-05,\n",
       "        3.33186035e-05, 8.13461884e-05],\n",
       "       [2.17538297e-01, 7.78894424e-01, 5.01578033e-04, 3.08185467e-04,\n",
       "        5.57636609e-04, 9.03550885e-04, 4.26798040e-04, 4.05714381e-04,\n",
       "        1.82425807e-04, 2.81304761e-04],\n",
       "       [3.88263822e-01, 6.04621053e-01, 9.50382149e-04, 4.06658190e-04,\n",
       "        1.75495993e-03, 1.58701430e-03, 4.77364287e-04, 6.83368358e-04,\n",
       "        2.82678782e-04, 9.72730049e-04],\n",
       "       [4.62675661e-01, 5.31665802e-01, 7.51517422e-04, 3.86972737e-04,\n",
       "        1.12471008e-03, 1.23765378e-03, 5.12741157e-04, 6.02011918e-04,\n",
       "        3.79555335e-04, 6.63416169e-04],\n",
       "       [5.29430807e-01, 4.65895504e-01, 7.29902938e-04, 3.88735527e-04,\n",
       "        8.76982231e-04, 9.74958297e-04, 6.15312078e-04, 3.90740024e-04,\n",
       "        2.98867002e-04, 3.98181117e-04],\n",
       "       [2.79944897e-01, 7.03080356e-01, 2.39773560e-03, 1.68564590e-03,\n",
       "        3.51658720e-03, 3.52103030e-03, 1.53046567e-03, 1.62609888e-03,\n",
       "        7.71060353e-04, 1.92612957e-03],\n",
       "       [2.13354707e-01, 7.81427383e-01, 7.24497717e-04, 3.86069267e-04,\n",
       "        1.26822561e-03, 1.22523715e-03, 4.32817062e-04, 4.12744121e-04,\n",
       "        2.42020076e-04, 5.26293472e-04],\n",
       "       [4.11048502e-01, 5.84733605e-01, 4.91609040e-04, 3.21734115e-04,\n",
       "        1.17516448e-03, 7.84068659e-04, 3.33623379e-04, 3.97662778e-04,\n",
       "        2.63861089e-04, 4.50162101e-04]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting a sample from the test df\n",
    "test_sample = test_df.sample(30)\n",
    "\n",
    "X_test_sample = test_sample.drop('class', axis=1)\n",
    "y_test_sample = test_sample['class']\n",
    "\n",
    "# making predictions using the loaded model\n",
    "predictions = model.predict(X_test_sample)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score    support\n",
      "0              0.625000  0.555556  0.588235   9.000000\n",
      "1              0.818182  0.857143  0.837209  21.000000\n",
      "accuracy       0.766667  0.766667  0.766667   0.766667\n",
      "macro avg      0.721591  0.706349  0.712722  30.000000\n",
      "weighted avg   0.760227  0.766667  0.762517  30.000000\n"
     ]
    }
   ],
   "source": [
    "# converting the predictions to class labels by computing the probabilities of class 1 or 0\n",
    "pred_labels = np.argmax(predictions, axis=1)  \n",
    "\n",
    "# computing the confusion matrix\n",
    "cm = confusion_matrix(y_test_sample, pred_labels)\n",
    "\n",
    "# defining class names - values of the target column [0, 1]\n",
    "class_names = y_test_df['class'].unique()\n",
    "\n",
    "# plotting the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  # Increase the size of the figure\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(ax=ax, cmap='Blues', xticks_rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "report = classification_report(y_test_sample, pred_labels, target_names=class_names, output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# report as a dataframe\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Improve Your Model\n",
    "\n",
    "Did your model achieve low loss (<0.1) and high accuracy (>0.95)? If not, try to improve your model.\n",
    "\n",
    "But how? There are so many things you can play with in Tensorflow and in the next challenge you'll learn about these things. But in this challenge, let's just do a few things to see if they will help.\n",
    "\n",
    "* Add more layers to your model. If the data are complex you need more layers. But don't use more layers than you need. If adding more layers does not improve the model performance you don't need additional layers.\n",
    "* Adjust the learning rate when you compile the model. This means you will create a custom `tf.keras.optimizers.Adam` instance where you specify the learning rate you want. Then pass the instance to `model.compile` as the optimizer.\n",
    "    * `tf.keras.optimizers.Adam` [reference](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n",
    "    * Don't worry if you don't understand what the learning rate does. You'll learn about it in the next challenge.\n",
    "* Adjust the number of epochs when you fit the training data to the model. Your model performance continues to improve as you train more epochs. But eventually it will reach the ceiling and the performance will stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 9)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19082 (74.54 KB)\n",
      "Trainable params: 19082 (74.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add more layers to the model\n",
    "model = tf.keras.models.load_model('tic-tac-toe.model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 9)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " modified_dense (Dense)      (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26698 (104.29 KB)\n",
      "Trainable params: 26698 (104.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating a new model by copying all layers up to the last one\n",
    "new_model = tf.keras.Sequential(model.layers[:-1])\n",
    "\n",
    "# adding the modified dense layer to the new model and the final output layer as before\n",
    "new_model.add(tf.keras.layers.Dense(units=64, activation='relu', name='modified_dense'))\n",
    "new_model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Build the new model\n",
    "new_model.build(input_shape=model.layers[0].input_shape)\n",
    "\n",
    "# Display the updated model summary\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "new_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "24/24 [==============================] - 2s 4ms/step - loss: 1.2418 - accuracy: 0.5457\n",
      "Epoch 2/3\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.7063\n",
      "Epoch 3/3\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f162753c50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(X_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5456849932670593, 0.75]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding an extra hidden layer increases the accuracy.\n",
    "# The evaluation for our first istance of 'model' was worse than this.\n",
    "new_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "24/24 [==============================] - 1s 3ms/step - loss: 0.5161 - accuracy: 0.7585\n",
      "Epoch 2/3\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7977\n",
      "Epoch 3/3\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8251\n",
      "6/6 [==============================] - 0s 397us/step - loss: 0.4719 - accuracy: 0.7969\n",
      "Learning Rate: 0.001, Accuracy: [0.471912145614624, 0.796875]\n",
      "Epoch 1/3\n",
      "24/24 [==============================] - 2s 4ms/step - loss: 0.5711 - accuracy: 0.7298\n",
      "Epoch 2/3\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8433\n",
      "Epoch 3/3\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3088 - accuracy: 0.8812\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7917\n",
      "Learning Rate: 0.01, Accuracy: [0.4489932954311371, 0.7916666865348816]\n",
      "Epoch 1/3\n",
      "24/24 [==============================] - 2s 3ms/step - loss: 2.0843 - accuracy: 0.6136\n",
      "Epoch 2/3\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6919\n",
      "Epoch 3/3\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7546\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.8229\n",
      "Learning Rate: 0.1, Accuracy: [0.44362008571624756, 0.8229166865348816]\n",
      "Epoch 1/3\n",
      "24/24 [==============================] - 2s 3ms/step - loss: 1.1516 - accuracy: 0.6410\n",
      "Epoch 2/3\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.6527\n",
      "Epoch 3/3\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6540\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6510\n",
      "Learning Rate: 0.3, Accuracy: [0.6577165126800537, 0.6510416865348816]\n",
      "Epoch 1/3\n",
      "24/24 [==============================] - 2s 3ms/step - loss: 0.6706 - accuracy: 0.6332\n",
      "Epoch 2/3\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6540\n",
      "Epoch 3/3\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.6149\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.6510\n",
      "Learning Rate: 0.5, Accuracy: [0.6688379645347595, 0.6510416865348816]\n"
     ]
    }
   ],
   "source": [
    "# Adjust the learning rate when you compile the model. This means you will create a custom `tf.keras.optimizers.Adam` instance where you specify the learning rate you want.\n",
    "# Then pass the instance to `model.compile` as the optimizer.\n",
    "models = tf.keras.models.load_model('tic-tac-toe.model')\n",
    "\n",
    "# Define a list of learning rates to test\n",
    "learning_rates_to_test = [0.001, 0.01, 0.1, 0.3, 0.5]\n",
    "\n",
    "# Iterate over each learning rate\n",
    "for learning_rate in learning_rates_to_test:\n",
    "    \n",
    "    custom_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=3)\n",
    "    evaluation_results = model.evaluate(X_test, y_test)\n",
    "\n",
    "    print(f\"Learning Rate: {learning_rate}, Accuracy: {evaluation_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best learning rate are the lowest ones (from 0.001 to 0.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "24/24 [==============================] - 2s 3ms/step - loss: 0.5202 - accuracy: 0.7676\n",
      "Epoch 2/3\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7885\n",
      "Epoch 3/3\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8107\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7865\n",
      "Epoch: 3, Accuracy: [0.4837433397769928, 0.7864583134651184]\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 1s 3ms/step - loss: 0.4077 - accuracy: 0.8342\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3811 - accuracy: 0.8590\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8629\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8956\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.8864\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8021\n",
      "Epoch: 5, Accuracy: [0.404144287109375, 0.8020833134651184]\n",
      "Epoch 1/8\n",
      "24/24 [==============================] - 1s 3ms/step - loss: 0.3024 - accuracy: 0.8982\n",
      "Epoch 2/8\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.9060\n",
      "Epoch 3/8\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2616 - accuracy: 0.9178\n",
      "Epoch 4/8\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.9204\n",
      "Epoch 5/8\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9373\n",
      "Epoch 6/8\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9360\n",
      "Epoch 7/8\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9413\n",
      "Epoch 8/8\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9465\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8750\n",
      "Epoch: 8, Accuracy: [0.31078019738197327, 0.875]\n",
      "Epoch 1/11\n",
      "24/24 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.9452\n",
      "Epoch 2/11\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.9608\n",
      "Epoch 3/11\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9661\n",
      "Epoch 4/11\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9726\n",
      "Epoch 5/11\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9621\n",
      "Epoch 6/11\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9791\n",
      "Epoch 7/11\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9869\n",
      "Epoch 8/11\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9869\n",
      "Epoch 9/11\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9909\n",
      "Epoch 10/11\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9909\n",
      "Epoch 11/11\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9922\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9271\n",
      "Epoch: 11, Accuracy: [0.1938028186559677, 0.9270833134651184]\n",
      "Epoch 1/14\n",
      "24/24 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9896\n",
      "Epoch 2/14\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9987\n",
      "Epoch 3/14\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9935\n",
      "Epoch 4/14\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 1.0000\n",
      "Epoch 5/14\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 6/14\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 1.0000\n",
      "Epoch 7/14\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 1.0000\n",
      "Epoch 8/14\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 9/14\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 10/14\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 11/14\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 12/14\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 13/14\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 14/14\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9635\n",
      "Epoch: 14, Accuracy: [0.11398559808731079, 0.9635416865348816]\n"
     ]
    }
   ],
   "source": [
    "# Adjust the number of epochs when you fit the training data to the model. \n",
    "# Your model performance continues to improve as you train more epochs. But eventually it will reach the ceiling and the performance will stay the same.\n",
    "# Define a list of learning rates to test\n",
    "model = tf.keras.models.load_model('tic-tac-toe.model')\n",
    "\n",
    "epochs_to_test = [3, 5, 8, 11, 14]\n",
    "\n",
    "# Iterate over each learning rate\n",
    "for epoch in epochs_to_test:\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=epoch)\n",
    "    evaluation_results = model.evaluate(X_test, y_test)\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Accuracy: {evaluation_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best accuracy was for epoch=14 - more the epochs, more the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which approach(es) did you find helpful to improve your model performance?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All approaches gave some results. Increasing epochs and decreasing the learning rate is good for accuracy, but not good for computational power (in this case the dataset is small and easy to process, so we don't see the disadvantages, but in most scenarios it will be a problem).\n",
    "# It also can lead to overfitting, so it would be wise to check how the model performs with a separate test set (here we did not split in train, validation and test, but only in train and test)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
